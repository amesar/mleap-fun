# MLeap Examples

Basic MLeap examples. 

Demonstrates end-to-end creation of an MLeap bundle and serving it as either a Spark bundle or MLeap bundle.

I was frustrated at the lack of working examples and light documentation from the MLeap site, so I created this sampler which demonstrates basic usage of MLeap with Spark ML.

#### Synopsis
* Versions:
  * Spark 2.4.4
  * MLeap 0.13.0
* Write an MLeap bundle that can be read by either Spark or MLeap without Spark
* Load and score using SparkBundle (does not score correctly)
  * Run Databricks job to load and score using SparkBundle (scores correctly)
* Load and score using MLeapBundle - no Spark code (scores correctly)
* DecisionTreeRegressor with wine quality dataset

#### MLeap Bundles
* You can use either the `file:` or `jar:file` scheme for the bundle URI.
  * `file:$PWD/../bundles/wine-model`
  * `jar:file:$PWD/../bundles/wine-model.zip`

#### MLflow MLeap Bundle

Besides the bundle generated by [SparkMLeapWriter.scala](spark_bundle/src/main/scala/org/andre/mleap/wine/SparkMLeapWriter.scala),
you can point to a bundle produced by MLflow.

[SparkMLeapReader.scala](spark_bundle/src/main/scala/org/andre/mleap/wine/SparkMLeapReader.scala) and [MLeapReader.scala](mleap_bundle/src/main/scala/org/andre/mleap/wine/MLeapReader.scala) can read the following identical model from MLflow.
  * https://github.com/amesar/mlflow-examples/tree/master/scala_spark
  * Sample local bundle path: `file:$HOME/mlflow/server/mlruns/2/853cd54adb3f4eabb94807b6aa9f8a0f/artifacts/mleap-model/mleap/model`
  * Or model download an MLeap bundle from Databricks DBFS: `dbfs:/databricks/mlflow/4294766/897e1769d6474e89970f2b4faddb7eff/artifacts/mleap-model/mleap/model`

#### Issues

The model loaded by `SparkMLeapReader.scala` does not score correctly as all predictions are 0.
If the jar is run against a Databricks ML 6.1 cluster the program does score correctly. See section below.

## Setup

* Install Spark 2.4.4.
* Install Scala 2.11.8.
* For Python usage: `pip install mleap`.

## SparkBundle
**Build jar**
```
cd spark_bundle
mvn clean package
```

**Write bundle**

SparkMLeapWriter will create a schema file in a Spark JSON schema format for the input data.
This file is only used by the MLeap bundle reader to create a LeapFrame.
See [samples/wine-schema.json](samples/wine-schema.json).

```
spark-submit \
  --class org.andre.mleap.spark.wine.SparkMLeapWriter \
  --master local[2] \
  target/mleap-spark-examples-1.0-SNAPSHOT.jar \
  --bundlePath jar:file:$PWD/../bundles/wine-model.zip \
  --dataPath ../data/wine-quality-white.csv \
  --schemaPath ../bundles/wine-schema.json
```

**Read and score Spark bundle**
```
spark-submit \
  --class org.andre.mleap.spark.wine.SparkMLeapReader \
  --master local[2] \
  target/mleap-spark-examples-1.0-SNAPSHOT.jar \
  --bundlePath jar:file:$PWD/../bundles/wine-model.zip \
  --dataPath ../data/wine-quality-white.csv
```

**Python write bundle**

You can also write a bundle with Python - see [write_bundle.py](spark_bundle/python/write_bundle.py).
```
cd python
spark-submit --master local[2] \
  --packages com.databricks:spark-avro_2.11:3.0.1,ml.combust.mleap:mleap-spark_2.11:0.12.0 \
  write_bundle.py \
  --bundle_path jar:file:$PWD/wine-model.zip
```

## MleapBundle

This module does not contain any Spark code.
[MLeapReader](mleap_bundle/src/main/scala/org/andre/mleap/wine/MLeapReader.scala)  uses the schema file created by SparkMLeapWriter.

**Build jar**
```
cd mleap_bundle
mvn clean package
```

**Read and score MLeap bundle**
```
scala \
  -cp target/mleap-examples-1.0-SNAPSHOT.jar \
  org.andre.mleap.wine.MLeapReader \
  --dataPath ../data/wine-quality-white.csv \
  --bundlePath jar:file:$PWD/../bundles/wine-model.zip \
  --schemaPath ../bundles/wine-schema.json
```

**Python read bundle**

See [read_bundle.py](spark_bundle/python/read_bundle.py).
Note that MLeap only supports deserialization with SparkBundle.
If you want to deserialize without using Spark you have to use the MLeapBundle with Scala.
```
cd python
spark-submit --master local[2] \
  --packages com.databricks:spark-avro_2.11:3.0.1,ml.combust.mleap:mleap-spark_2.11:0.12.0 \
  write_bundle.py \
  --bundle_path jar:file:$PWD/wine-model.zip
```

## Running SparkBundleReader on Databricks

SparkBundleReader works correctly on a Databricks cluster.

Copy artifacts to DBFS.
```
cd spark_bundle
databricks fs mkdirs dbfs:/tmp/mleap-fun
databricks fs cp target/mleap-spark-examples-1.0-SNAPSHOT.jar dbfs:/tmp/mleap-fun
databricks fs cp ../data/wine-quality-white.csv dbfs:/tmp/mleap-fun
databricks fs cp ../bundles/wine-model.zip dbfs:/tmp/mleap-fun
databricks fs cp wine-schema.json dbfs:/tmp/mleap-fun
```

Run the job on the cluster.
```
databricks runs submit --json-file run_submit.json
```
